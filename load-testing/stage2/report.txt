Отчет о проделанной работе: Репликация

1. Составлен план нагрузочного тестирования включающий следующий сценарий:
-Пользователь, с идентификатором из подготовленного списка идентификаторов пользователей, вызывает метод login;
-С полученным токеном из первого шага вызывается метод get_user; 
-Вызывается метод search_user;
2. Выполнены замеры производительности с планом из первого шага.
3. Реализована настройка потоковой репликации БД на 2 реплики, конфигурация в docker-compose.yaml.
4. Следующий этап - реализовать работу приложения с кластером: запросы на чтение данных отправлять на реплики, запись - на мастер.

Рассмотренные варианты:
4.1. В качестве балансировщика запросов я настроил pgpool (docker-compose.yaml) в коде изменил порт БД на порт pgpool.
В целом, система на такой конфигурации показала работоспособность как на чтение, так и на запись, в логах pgpool видно распределение по репликам, но замеры производительности не показали прироста, 
напротив, latency и времена отклика стали существенно хуже. В процессе анализа данной ситуации, выяснилось, что на это повлияли запросы с помощью prepared_statement в коде - в случае работы через pgpool
prepared_statement показывает ухудшение производительности из-за распределения запросов на разные инстансы БД. В коде я отказался от prepared_statement в пользу обычных query. Это сняло проблему с сильной просадкой
производительности, но, как показали замеры, производительность все равно была чуть хуже, чем без использования pgpool.
Поэтому, я стал смотреть следующий вариант.
4.2. В коде я выделил отдельную сущность - пул соединений с репликами, с ручной случайной балансировкой в коде.
Такая конфигурация также не показала прироста производительности. Кроме того, я обнаружил, что один из запросов - login, работает намного дольше search и get_user - 800мс против 100-200мс на низкой нагрузке. 
Вероятно, этот эффект обусловлен использованием криптографического алгоритма кодирования пароля. Запрос login в коде я посадил на работу с мастером для того, чтобы не засорять результаты.
4.3. Для того, чтобы все-таки увидеть в коде увеличение производительности при использовании реплик я попытался имитировать "узкое горлышко" на мастере - ввел для мастера ограничение ресурсов.
Выполнил замеры производительности, когда все пулы в коде смотрят на мастер с различными вариантами ограничений ресурсов;
Выполнил замеры с использованием реплик. В таком варианте тоже увидеть прирост производительности не удалось - при использовании только мастера достичь исчерпания ресурсов оказалось не проблема, но в случае, когда мастер захлебывается
запросами просто запросы начинают отваливаться по таймауту и завершаться ошибкой. Единственный бонус, который можно было тут увидеть - при использовании кластера, тот же тест нагрузки система вывозит без ошибок.
4.4 Еще эксперементировал с удалением индексов, тогда запросы search резко начинают грузить БД, что выливается в отказы, аналогично предыдущему пункту.

5. Замеры производительности не показали прироста по сравнению с конфигурацией без репликации.

6. Кворумную репликацию не делал

7. Эксперименты с записью на мастер. Для автоматического промоутинга до мастера переключился на использование настренного ранее pgpool.
Написал тест план записи (регистрация пользователей), запустил нагрузку записи.

8. В процессе работы нагрузочного процесса на запись отключил мастер-узел. Пронаблюдал переключение реплики 1 в режим мастера и восстановление работоспособности системы. 
При этом отпадает 9-10 транзакций (Нагрузка записи шла в 100 потоков).



